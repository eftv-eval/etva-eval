<!DOCTYPE html>
<html>
<head>

  <meta charset="utf-8">
  <meta name="description"
        content="ETVA: Evaluation of Text-to-Video Alignment via Fine-grained Question Generation and Answering">
  <meta name="keywords" content="Evaluation, Benchmark, Prompts, Dataset, Video Generation, Text-to-Video">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ETVA: Evaluation of Text-to-Video Alignment via Fine-grained Question Generation and Answering</title>

<!--   Global site tag (gtag.js) - Google Analytics-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y5ZVQZ7NHC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-Y5ZVQZ7NHC');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">

  <link rel="stylesheet" href="./assets/css/bulma.min.css">
  <link rel="stylesheet" href="./assets/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./assets/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./assets/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./assets/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./assets/js/fontawesome.all.min.js"></script>
  <script src="./assets/js/bulma-carousel.min.js"></script>
  <script src="./assets/js/bulma-slider.min.js"></script>
  <script src="./assets/js/index.js"></script>
</head>
<body>

<!-- title -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title"><span style="color:#B9770E; font-weight: bold; font-style: italic">ETVA</span>: Evaluation of Text-to-Video Alignment via Fine-grained Question Generation and Answering</h1>
              <span class="author-block">
                  <a href="https://ziqihuangg.github.io" target="_blank">Kaisi Guan</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                  <a href="https://github.com/yinanhe" target="_blank">Zhengfeng Lai</a><sup>2</sup>,
              </span>
              <span class="author-block">
                  <a href="" target="_blank">Yuchong Sun</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://github.com/zhangfan-p" target="_blank">Peng Zhang</a><sup>2</sup>,
              </span>
              <br>
              <span class="author-block">
                  <a href="https://chenyangsi.top/" target="_blank">Wei Liu</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://yumingj.github.io/" target="_blank">Xiaojiang Liu</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://zhangyuanhan-ai.github.io/" target="_blank">Meng Cao</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://tianxingwu.github.io/" target="_blank">Ruihua Song</a><sup>1&#8224</sup>,
              </span>
          <!-- <br> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block">(&#8224 corresponding authors) </span>
        </div>

        <div class="is-size-5 publication-authors">
          <span class="author-block">
            <sup>1</sup>
            Gaoling School of Artificial Intelligence, Renmin University of China &nbsp;&nbsp;
            <sup>2</sup>
            Apple &nbsp;&nbsp;
          </span>
        </div>

        <div class="column has-text-centered">
          <div class="publication-links">
            
            <span class="link-block">
              <a href="https://eftv-eval.github.io/etva-eval/" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>Paper</span>
              </a>
            </span>
            <!-- Code Link. -->
            <span class="link-block">
              <a href="https://eftv-eval.github.io/etva-eval/" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code (Coming Soon)</span>
              </a>
            </span>
            <!-- Huggingface Dataset Link. -->
            <span class="link-block">
              <a href="https://eftv-eval.github.io/etva-eval/" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <img src="assets/hf-logo.svg" style="display:block;width:330px;height:240px" />
                </span>
                <span>Dataset (Comming Soon)</span>
              </a>
            </span>
          </div>

        </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero caser">
  <div class="container is-max-desktop" style="width: 65%; max-width: none;">
      <div class="hero-body">
            <img src="assets/images/case.png" style="width:100%; margin-bottom:10px" alt="Case."/>
      <p style="margin-top: 0;">
        <span style="color:#B9770E; font-weight: bold; font-style: italic">ETVA</span> is a text-to-video alignment evaluation framework that provides fine-grained assessment scores highly consistent with human judgment.
      </p>
    </div>
  </div>
</section>
<!-- Abstract. -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3"> 
      Abstract</h2>
  </div>
  </section>
<section>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered" style="margin-top: 10px; margin-bottom: 0px;">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            Precisely evaluating semantic alignment between text prompts and generated videos remains a challenge in Text-to-Video (T2V) Generation. Existing <b>text-to-video alignment</b> metrics like CLIPScore only generate coarse-grained scores without fine-grained alignment details, failing to align with human preference. To address this limitation, we propose <b>ETVA</b>, a novel <b>Evaluation method of Text-to-Video Alignment via fine-grained question generation and answering</b>. First, a multi-agent system parses prompts into semantic scene graphs to generate atomic questions. Then we design a knowledge-augmented multi-stage reasoning framework for question answering, where an auxiliary LLM first retrieves relevant common-sense knowledge (e.g., physical laws), and then video LLM answer the generated questions through a multi-stage reasoning mechanism. Extensive experiments demonstrate that ETVA achieves a <b>Spearmanâ€™s correlation coefficient of 58.47</b>, showing much higher correlation with human judgment than existing metrics which attain only 31.0. We also construct a comprehensive benchmark specifically designed for text-to-video alignment evaluation, featuring <b>2k diverse prompts</b> and <b>12k atomic questions</b> spanning 10 categories. Through a systematic evaluation of <b>15 existing text-to-video models</b>, we identify their key capabilities and limitations, paving the way for next-generation T2V generation. 
          </p>
        </div>
      </div>
    </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop" style="width: 50%; max-width: none;">
      <div class="hero-body">
            <img src="assets/images/teaser.pdf" style="width:90%; margin-bottom:10px" alt="Teaser."/>
      <p style="margin-top: 0;">
        Figure 1. llustration of how ETVA works and comparison with existing metrics.
      </p>
    </div>
  </div>
</section> -->
<!--/ Abstract. -->

<!-- Method. -->
<!--/ Method. -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3"> 
      Our ETVA Approach</h2>
  </div>
  </section>

<section class="hero caser">
  <div class="container is-max-desktop" style="width: 50%; max-width: none;">
      <div class="hero-body">
      <p style="margin-bottom: 30px;">
        ETVA contains a <b>multi-agent framework</b> for generating atomic questions and a <b>knowledge-augmented multi-stage reasoning framework</b> for question answering.
      </p>
      <img src="assets/images/method.png" style="width:100%; margin-bottom:10px" alt="Case."/>
    </div>
  </div>
</section>
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3"> 
      Our Proposed ETVABench</h2>
  </div>
</section>
<section class="hero caser">
  <div class="container is-max-desktop" style="width: 50%; max-width: none;">
      <div class="hero-body">
      <p style="margin-bottom: 30px;">
        We construct <b>ETVABench-2k</b> for evaluating Open-Source Text-to-Video models and <b>ETVABench-105</b> for evaluating Open-Source and Closed-Source Text-to-Video models. A question-driven classification method decomposes these prompts to <b>10 distinct categories</b>.
      </p>
      <img src="assets/images/category.png" style="width:100%; margin-bottom:10px" alt="Case."/>
      <img src="assets/images/prompts.png" style="width:100%; margin-bottom:10px" alt="Case."/>
    </div>
  </div>
</section>
<!-- LeaderBoard -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3"> 
      LeaderBoard</h2>
  </div>
</section>



<!-- Radar_Open Source -->
<section class="section" style="margin-top:-50px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="section-title">
          <h2 class="title is-3 is-centered">Evaluation Results on EFTVBench-105</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="assets/images/benchmark1.png" style="width:1000px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p style="margin-top: 0;">
          We visualize the evaluation results of <b>10 open sourced Text-to-Video models</b> and <b>5 closed sourced Text-to-Video models</b> across 10 dimensions on ETVABench-105. 
        </p>
        
    </div>
  </div>
</section>


<section class="section" style="margin-top:-150px; margin-bottom:-50px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div class="section-title">
          <h2 class="title is-3 is-centered">Evaluation Results on EFTVBench-2k</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="assets/images/radar.png" style="width:600px; margin-top:10px;margin-bottom:10px;"/>
            </div>
          </div>
        </div>
        <p style="margin-top: 0;">
          We visualize the evaluation results of <b>10 open sourced Text-to-Video models</b> across 10 dimensions on EFTVBench-2k.
        </p>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h2 class="title is-3"> 
      More Examples</h2>
  </div>
  </section>

<section class="section"  style="margin-top:-50px; margin-bottom:-140px;">
  <div class="hero-body">

    <div class="container is-max-desktop">


      <div class="section-title">
        <!-- <h2 class="title is-3">Video Quality Dimensions</h2> -->
        <h2 class="subtitle has-text-centered">Example 1:  Water is slowly pouring out of glass cup in the space station.</h2>
      </div>
      <!-- Single Line -->
      <div id="results-carousel-face" class="carousel results-carousel">
        <div class="item item-puppet">
          <div class="carousel-content">
                <video id="dimensions" autoplay="" muted="" loop="" playsinline="" height="100%">
                <source src="assets/vbench/images/dim_results/ppt_mp4_v3/flicker_and_subject.mp4" type="video/mp4">
              </video>
          </div>
        </div>
        <div class="item item-round_bird">
          <div class="carousel-content">
                <video id="dimensions" autoplay="" muted="" loop="" playsinline="" height="100%">
                <source src="assets/vbench/images/dim_results/ppt_mp4_v3/backdround_and_motion.mp4" type="video/mp4">
              </video>      
          </div>
        </div>
        <div class="item item-puppet">
          <div class="carousel-content">
            <video id="dimensions" autoplay="" muted="" loop="" playsinline="" height="100%">
              <source src="assets/vbench/images/dim_results/ppt_mp4_v3/dynamic_and_aesthetic.mp4" type="video/mp4">
            </video>    
          </div>
        </div>
        <div class="item item-round_bird">
          <div class="carousel-content">
                <video id="dimensions" autoplay="" muted="" loop="" playsinline="" height="100%">
                <source src="assets/vbench/images/dim_results/ppt_mp4_v3/technical_and_flicker.mp4" type="video/mp4">
              </video>      
          </div>
        </div>
      </div>
    
  </div>
</section>

<section class="section"  style="margin-top:-50px; margin-bottom:-140px;">
  <div class="hero-body">

    <div class="container is-max-desktop">


      <div class="section-title">
        <!-- <h2 class="title is-3">Video Quality Dimensions</h2> -->
        <h2 class="subtitle has-text-centered">Example 2:  Water is slowly pouring out of glass cup in the space station.</h2>
      </div>
      <!-- Single Line -->
      <div id="results-carousel-face" class="carousel results-carousel">
        <div class="item item-puppet">
          <div class="carousel-content">
                <video id="dimensions" autoplay="" muted="" loop="" playsinline="" height="100%">
                <source src="assets/vbench/images/dim_results/ppt_mp4_v3/flicker_and_subject.mp4" type="video/mp4">
              </video>
          </div>
        </div>
        <div class="item item-round_bird">
          <div class="carousel-content">
                <video id="dimensions" autoplay="" muted="" loop="" playsinline="" height="100%">
                <source src="assets/vbench/images/dim_results/ppt_mp4_v3/backdround_and_motion.mp4" type="video/mp4">
              </video>      
          </div>
        </div>
        <div class="item item-puppet">
          <div class="carousel-content">
            <video id="dimensions" autoplay="" muted="" loop="" playsinline="" height="100%">
              <source src="assets/vbench/images/dim_results/ppt_mp4_v3/dynamic_and_aesthetic.mp4" type="video/mp4">
            </video>    
          </div>
        </div>
        <div class="item item-round_bird">
          <div class="carousel-content">
                <video id="dimensions" autoplay="" muted="" loop="" playsinline="" height="100%">
                <source src="assets/vbench/images/dim_results/ppt_mp4_v3/technical_and_flicker.mp4" type="video/mp4">
              </video>      
          </div>
        </div>
      </div>
    
  </div>
</section>



<!-- <section class="hero is-light is-small" id="BibTeX" >
  <div class="container is-max-desktop content" style="margin-top: 40px; margin-bottom: 20px;">
    <h2 class="title">BibTeX</h2>
    <p>If you find our work useful, please consider citing our paper:</p>
    <pre><code>@InProceedings{huang2023vbench,
      title={{VBench}: Comprehensive Benchmark Suite for Video Generative Models},
      author={Huang, Ziqi and He, Yinan and Yu, Jiashuo and Zhang, Fan and Si, Chenyang and Jiang, Yuming and Zhang, Yuanhan and Wu, Tianxing and Jin, Qingyang and Chanpaisit, Nattapol and Wang, Yaohui and Chen, Xinyuan and Wang, Limin and Lin, Dahua and Qiao, Yu and Liu, Ziwei},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
      year={2024}
}

@article{huang2024vbench++,
  title={VBench++: Comprehensive and Versatile Benchmark Suite for Video Generative Models},
  author={Huang, Ziqi and Zhang, Fan and Xu, Xiaojie and He, Yinan and Yu, Jiashuo and Dong, Ziyue and Ma, Qianli and Chanpaisit, Nattapol and Si, Chenyang and Jiang, Yuming and Wang, Yaohui and Chen, Xinyuan and Chen, Ying-Cong and Wang, Limin and Lin, Dahua and Qiao, Yu and Liu, Ziwei},
  journal={arXiv preprint arXiv:2411.13503},
  year={2024}
}</code></pre>
  </div>
</section> -->




<!-- footer -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://eftv-eval.github.io/etva-eval/">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://eftv-eval.github.io/etva-eval/" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>


